{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXHLDxJdRzBi"
      },
      "source": [
        "# **Identifying Challenges Faced by Developers in Scientific Workflow Management Systems using BERTopic**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook uses BERTopic to identify challenges faced by developers in scientific workflow management systems using Stack Overflow posts and GitHub issues. The dataset used in this notebook is available at https://figshare.com/projects/SWsChallengesbySOandGitHub/172476."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Installing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNa-KtKDRnus",
        "vscode": {
          "languageId": "powershell"
        }
      },
      "outputs": [],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3VGFZ1USMTu"
      },
      "source": [
        "## Define functions to preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJij3WP6SEQD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bertopic import BERTopic\n",
        "\n",
        "# Download stopwords if not already available\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Custom stopwords list (add domain-specific stopwords if needed)\n",
        "custom_stopwords = set([])\n",
        "\n",
        "def clean_text(text):\n",
        "    # Remove HTML tags using BeautifulSoup\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    text = soup.get_text()\n",
        "\n",
        "    # Remove non-alphanumeric characters and convert to lowercase\n",
        "    text = re.sub(r'[^A-Za-z\\s]', ' ', text.lower())\n",
        "\n",
        "    # Remove extra whitespaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "def remove_stopwords_and_lemmatize(text):\n",
        "    stop_words = set(stopwords.words('english')) | custom_stopwords\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    return \" \".join(lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words)\n",
        "\n",
        "def train_bertopic(data):\n",
        "    model = BERTopic(language=\"english\", calculate_probabilities=True)\n",
        "    topics, probabilities = model.fit_transform(data)\n",
        "    return model, topics, probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBcNmZJzSTY8"
      },
      "source": [
        "## Import and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the data\n",
        "try:\n",
        "    new_df = pd.read_csv('Dataset/StackOverflowPostsDataset.csv')\n",
        "    new_df[\"merged\"] = new_df[[\"Body\", \"Title\", \"Tags\"]].apply(\"-\".join, axis=1)\n",
        "except FileNotFoundError:\n",
        "    print(\"Dataset file not found. Please provide the correct file path.\")\n",
        "    exit(1)\n",
        "\n",
        "# Preprocess the data\n",
        "new_df[\"merged\"] = new_df[\"merged\"].apply(clean_text)\n",
        "new_df[\"processed\"] = new_df[\"merged\"].apply(remove_stopwords_and_lemmatize)\n",
        "\n",
        "# Save the preprocessed data\n",
        "new_df.to_csv('Results/ConcatenatedDatasetSO.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# View first 5 rows of the processed data\n",
        "print(new_df.head()[\"processed\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QI6vwelqnTL-"
      },
      "source": [
        "## Building and training the model\n",
        "\n",
        "Instantiate the model and train it on the data. The model will automatically select the best topic based on the topic coherence. The higher the topic coherence, the better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TfhfzqkoSJ1I"
      },
      "outputs": [],
      "source": [
        "# Train BERTopic on processed data\n",
        "data = new_df[\"processed\"].values.tolist()\n",
        "model, topics, probabilities = train_bertopic(data)\n",
        "\n",
        "# Get topics and their top words\n",
        "topics_df = model.get_topic_freq()\n",
        "topics_df.head()\n",
        "\n",
        "# Save the BERTopic model\n",
        "model.save(\"Results/BERTopicModelSO\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5O3KpHTnVpz"
      },
      "source": [
        "## Extracting Topics\n",
        "After fitting the model, we can extract the topics from the model. This will return the topics with their corresponding IDs, the dominant topic per sentence, and the frequency of each topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ScBUgXn06IK6",
        "outputId": "ee49a346-8d12-41c4-c7e9-8c1b6782c636"
      },
      "outputs": [],
      "source": [
        "freq = model.get_topic_info(); freq.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BtOgifV7Q-H"
      },
      "source": [
        "-1 refers to all outliers that BERTopic was not able to assign a topic to. Next, look at the most frequent topics and their words to determine what the topic is about."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVpvT4bA6KiN",
        "outputId": "9cf99b89-30bb-45fe-b98b-063f8f3624d9"
      },
      "outputs": [],
      "source": [
        "model.get_topic(0)  # Select the most frequent topic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j91cP3xBpWDM"
      },
      "source": [
        "## Assess trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCMHaWVMpbo3"
      },
      "outputs": [],
      "source": [
        "# assess predicted topics for first 10 posts\n",
        "model.topics_[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8c8LenB8Zyl"
      },
      "source": [
        "## Visualize Topics\n",
        "After having trained our model, we can visualize the topics that were generated in a way very similar to LDAvis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "S9qDqEHddgKq",
        "outputId": "3fddd5f1-194e-4708-a7dc-f0c5602c140a"
      },
      "outputs": [],
      "source": [
        "model.visualize_topics()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.visualize_distribution(probabilities[70], min_probability=0.015)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize topic hierarchy\n",
        "model.visualize_hierarchy(top_n_topics=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize terms\n",
        "model.visualize_barchart(top_n_topics=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize topic similarity\n",
        "model.visualize_heatmap(n_clusters=20, width=1000, height=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize term score decline\n",
        "model.visualize_term_rank()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Refine Model\n",
        "\n",
        "Our model has identified over 70 different topics, which is a bit too many to be useful. We can fine-tune the model by adjusting the parameters and retraining the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# update topics to include bigrams and trigrams\n",
        "model.update_topics(data, n_gram_range=(1, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get top words and their c-TF-IDF scores\n",
        "model.get_topic(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get topic frequencies\n",
        "model.get_topic_freq()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BERTopic.load(\"Results/BERTopicModelSO\")\n",
        "\n",
        "# reduce topics\n",
        "model.reduce_topics(data, nr_topics=32)\n",
        "print(model.topics_)\n",
        "\n",
        "# visualize reduced topics\n",
        "model.visualize_topics()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
